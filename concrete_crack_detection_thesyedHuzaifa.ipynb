{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuwejDMi_BWJ"
   },
   "source": [
    "concrete crack detection using deep neural network\n",
    "",
    "\n",
    "",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SvNybLUn3tA",
    "outputId": "c6974476-2f6d-49ce-b91f-eb4ac8f0b84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Found 14986 images belonging to 2 classes.\n",
      "Epoch 1/35\n",
      "59/59 [==============================] - 65s 1s/step - loss: 1.4187 - accuracy: 0.5302\n",
      "Epoch 2/35\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.6730 - accuracy: 0.5906\n",
      "Epoch 3/35\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.6202 - accuracy: 0.6583\n",
      "Epoch 4/35\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.5785 - accuracy: 0.7060\n",
      "Epoch 5/35\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.5608 - accuracy: 0.7116\n",
      "Epoch 6/35\n",
      "59/59 [==============================] - 59s 1s/step - loss: 0.5505 - accuracy: 0.7275\n",
      "Epoch 7/35\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.5241 - accuracy: 0.7506\n",
      "Epoch 8/35\n",
      "59/59 [==============================] - 58s 981ms/step - loss: 0.5152 - accuracy: 0.7551\n",
      "Epoch 9/35\n",
      "59/59 [==============================] - 57s 958ms/step - loss: 0.4851 - accuracy: 0.7743\n",
      "Epoch 10/35\n",
      "59/59 [==============================] - 57s 956ms/step - loss: 0.4853 - accuracy: 0.7739\n",
      "Epoch 11/35\n",
      "59/59 [==============================] - 56s 946ms/step - loss: 0.4615 - accuracy: 0.7901\n",
      "Epoch 12/35\n",
      "59/59 [==============================] - 57s 954ms/step - loss: 0.4561 - accuracy: 0.7927\n",
      "Epoch 13/35\n",
      "59/59 [==============================] - 56s 949ms/step - loss: 0.4499 - accuracy: 0.7951\n",
      "Epoch 14/35\n",
      "59/59 [==============================] - 56s 951ms/step - loss: 0.4307 - accuracy: 0.8104\n",
      "Epoch 15/35\n",
      "59/59 [==============================] - 56s 944ms/step - loss: 0.4388 - accuracy: 0.7997\n",
      "Epoch 16/35\n",
      "59/59 [==============================] - 56s 944ms/step - loss: 0.4289 - accuracy: 0.8103\n",
      "Epoch 17/35\n",
      "59/59 [==============================] - 56s 950ms/step - loss: 0.4135 - accuracy: 0.8205\n",
      "Epoch 18/35\n",
      "59/59 [==============================] - 56s 947ms/step - loss: 0.4100 - accuracy: 0.8207\n",
      "Epoch 19/35\n",
      "59/59 [==============================] - 56s 951ms/step - loss: 0.4341 - accuracy: 0.8059\n",
      "Epoch 20/35\n",
      "59/59 [==============================] - 56s 943ms/step - loss: 0.4132 - accuracy: 0.8199\n",
      "Epoch 21/35\n",
      "59/59 [==============================] - 56s 943ms/step - loss: 0.3934 - accuracy: 0.8326\n",
      "Epoch 22/35\n",
      "59/59 [==============================] - 57s 959ms/step - loss: 0.3926 - accuracy: 0.8364\n",
      "Epoch 23/35\n",
      "59/59 [==============================] - 56s 940ms/step - loss: 0.4051 - accuracy: 0.8250\n",
      "Epoch 24/35\n",
      "59/59 [==============================] - 56s 939ms/step - loss: 0.3936 - accuracy: 0.8325\n",
      "Epoch 25/35\n",
      "59/59 [==============================] - 56s 946ms/step - loss: 0.3847 - accuracy: 0.8390\n",
      "Epoch 26/35\n",
      "59/59 [==============================] - 56s 943ms/step - loss: 0.3688 - accuracy: 0.8457\n",
      "Epoch 27/35\n",
      "59/59 [==============================] - 56s 942ms/step - loss: 0.3802 - accuracy: 0.8394\n",
      "Epoch 28/35\n",
      "59/59 [==============================] - 56s 948ms/step - loss: 0.3773 - accuracy: 0.8415\n",
      "Epoch 29/35\n",
      "59/59 [==============================] - 56s 939ms/step - loss: 0.3617 - accuracy: 0.8495\n",
      "Epoch 30/35\n",
      "59/59 [==============================] - 56s 947ms/step - loss: 0.3580 - accuracy: 0.8522\n",
      "Epoch 31/35\n",
      "59/59 [==============================] - 56s 938ms/step - loss: 0.3473 - accuracy: 0.8596\n",
      "Epoch 32/35\n",
      "59/59 [==============================] - 56s 939ms/step - loss: 0.3553 - accuracy: 0.8569\n",
      "Epoch 33/35\n",
      "59/59 [==============================] - 56s 944ms/step - loss: 0.3684 - accuracy: 0.8459\n",
      "Epoch 34/35\n",
      "59/59 [==============================] - 56s 942ms/step - loss: 0.3492 - accuracy: 0.8576\n",
      "Epoch 35/35\n",
      "59/59 [==============================] - 56s 943ms/step - loss: 0.3420 - accuracy: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8986bef400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL  \n",
    "\n",
    "#IMPORTING required libraries\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Set path to input data\n",
    "drive_path = '/content/drive/MyDrive/MLASSIGNMENT2'\n",
    "train_path = os.path.join(drive_path, 'train')\n",
    "test_path = os.path.join(drive_path, 'test')\n",
    "\n",
    "# Set up data augmentation parameters\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data using the generator\n",
    "train_generator = datagen.flow_from_directory(train_path, target_size=(224,224), batch_size=256, class_mode='binary')\n",
    "\n",
    "#The weights of pre-trained MobileNetV2 model are used.\n",
    "\n",
    "# Loading the pre-trained MobileNetV2 model\n",
    "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freezing the layers in the pre-trained model\n",
    "for layer in mobilenetv2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Defining the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(mobilenetv2)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_generator, epochs=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_79QI9mq_OrJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0JUROqyK4V5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVX1jotDWHhg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1bJhiiLn99c",
    "outputId": "93916e02-4ec1-4da1-8eb8-634c0b1ac207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 1 classes.\n",
      "2000/2000 [==============================] - 22s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "#Loading the test data\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Making predictions on the test data\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict(test_generator)#, steps=np.ceil(nb_samples))\n",
    "\n",
    "# Converting the predicted probabilities to class labels\n",
    "class_labels = []\n",
    "for p in predict:\n",
    "    if p < 0.5:\n",
    "        class_labels.append('cracked')\n",
    "    else:\n",
    "        class_labels.append('uncracked')\n",
    "filenames2=[]\n",
    "for file in filenames:\n",
    "  filenames2.append(file.split('/')[1])\n",
    "\n",
    "# Creating a DataFrame with the filenames and class labels\n",
    "results = pd.DataFrame({'filename': filenames2, 'class': class_labels})\n",
    "os.chdir('/content/drive/MyDrive/MLASSIGNMENT2')\n",
    "\n",
    "# Saving the results to a CSV file\n",
    "results.to_csv('results_ep35.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBzDnXsMNRcH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52t76Vn0kKSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofJAKZLq7DIl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4uqr-noR7-V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UodywqP1o00c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMe2Fb3JxuEo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeORkCbuIm6y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEGoMBh-ffwZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
